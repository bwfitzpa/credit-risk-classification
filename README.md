# credit-risk-classification
## Overview of the Analysis
### Purpose of the analysis
The purpose of this analysis was to build and train a model to determine if a loan will be risky or not. This was done to help determine which loans should or should not be made in the future.
### Financial information that the data was on and what needed to be predicted
The data used was on peer-to-peer lending and from a peer-to-peer lending company. The goal was to predict how credit worthy a borrower is. The prediction was made using the features loan size, interest rate, borrower income, debt to income, number of accounts, derogatory marks, and total debt.
### Info about variable that I was trying to predict
The variable that was predicted is loan status. This variable is binary and coded as 0 if the loan is healthy, and as 1 if the loan is at a high-risk of default. 75,036 loans were classified as healthy, while 25,00 were classified as high-risk.
### Stages of the machine learning process and methods used
Two machine learning models were used, one using logistic regression and another using logistics regression with over sampling of the labels. Oversampling was used in the second model because of the in-balance in healthy versus high-risk loans. The stages of the machine learning process for each of the models were the same, except for the use of oversampling in the second model. 
First the labels (loan status) were separated from the data, and then the features (loan size, interest rate, borrower income, debt to income, number of accounts, derogatory marks, and total debt) were separated and scaled using StandardScaler. StandardScaler was used because of the large differences in some of the scales of the features. The module train_test_split from sklearn was then used to split the data into training and testing data. The logistic model was then instantiated, and the model was fit using the training data. From this model predictions were then made and compared to the test data. Each of the models' performance were then examined using an balanced accuracy score, a confusion matrix, and a classification report.
## Results of accuracy, precision and recall scores
### Machine learning model using logistic regression
* Accuracy: The logistic regression model overall does a respectable job of predicting loan status, with an accuracy score of 0.986. Showing this model is correct when predicting if a loan is healthy or high-risk 98.6% of the time.
* Precision: The precision for healthy loans is 1.00, while the precision for high-risk loans is 0.87. The weighted average of these two scores is 1.00. Showing overall the precision of the model is high, but also that precision is much lower when it comes to predicting high-risk loans.
* Recall Scores: The recall ratio for the healthy loans is 1.00, and 0.98 for the high-risk loans. The weighted average of these two is 0.99. This shows for both the healthy loans and the high-risk loans the model is doing a fairly decent job at predicting the loan outcome.
### Machine learning model using logistic regression and oversampling
* Accuracy: The logistic regression model fit with oversampled data does a good job of predicting overall loan status, with an accuracy score of 0.996. Showing this model is correct when predicting if a loan is healthy or high-risk 99.6% of the time.
* Precision: The precision for healthy loans is 1.00, while the precision for high-risk loans is 0.87. The weighted average of these two scores is 1.00. Showing overall the precision of the model is high, but also that precision is much lower when it comes to predicting high-risk loans.
* Recall Scores: The recall ratio for the healthy loans is 0.99, and 1.00 for the high-risk loans. The weighted average of these two is 0.99. This shows for both the healthy loans and the high-risk loans the model is doing a fairly decent job at predicting the loan outcome.

## Summary of the results comparing the two models and recommendation
I would recommend using the second model that used oversampling, but with the caveat that there is room for improvement of this model. That is, the second model is the best one out of the two but the model is not perfect, however as more data are added the performance of the model should improve. The underlying issue as to why both models are doing a worse job of predicting high-risk versus healthy loans is loan status is unbalanced, there are 75,036 healthy loans, but only 2,500 high-risk loans. This said, this is a good problem to have because it means the vast majority of loans are healthy loans and only a few loans are risky. Thus, the vetting process to determine who should get a loan is working fairly well. But given that some loans are still risky there is room for improvement. This is also why using oversampling in the second model leads to better performance.

There are a few reasons for choosing the second model over the first one. First, when comparing accuracy scores the second model performs about a percent better than the first one. However, the main reason for choosing the second model over the first one is that that second model does a better job at predicting what loans will be high-risk. It is more important to be accurate in predicting which loans will be high-risk because if a borrower defaults on their loan this comes with a large financial hit to the lender. While predicting healthy loans is important, if the model does not perform as well at predicting healthy loans this might lead to less borrowers getting loans but it will not lead to increased risk to the lender, although it could lead to less profits as fewer loans would be made.

When comparing the performance of the second model to the first model when it comes to predicting high-risk loans both have a precision of 0.87 at predicting healthy loans, however the second model has a recall score of 1.00 while the first model has a recall score of 0.98, thus the second model is performing slightly better when it comes to predicting high-risk loans. Then when examining the confusion matrix for each model, the actual high-risk loans that were predicted as being healthy are 14 in the results of the first model, but they are only 2 in the results of the second model. This gives another reason to pick the second model over the first one.
